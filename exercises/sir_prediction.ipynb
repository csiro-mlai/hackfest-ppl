{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def covidlive_data(start_date=np.datetime64('2021-06-10')):\n",
    "    df = pd.read_html('https://covidlive.com.au/report/daily-source-overseas/nsw')[1]\n",
    "\n",
    "    df = df[:200]\n",
    "\n",
    "    if df['NET2'][0] == '-':\n",
    "        df = df[1:200]\n",
    "\n",
    "    dates = np.array(\n",
    "        [\n",
    "            np.datetime64(datetime.strptime(date, \"%d %b %y\"), 'D') - 1\n",
    "            for date in df['DATE']\n",
    "        ]\n",
    "    )\n",
    "    cases = np.array(df['NET2'].astype(int))\n",
    "    cases = cases[dates >= start_date][::-1]\n",
    "    dates = dates[dates >= start_date][::-1]\n",
    "\n",
    "    return dates, cases\n",
    "\n",
    "base = datetime(2021, 8, 1)\n",
    "arr = np.array([base + timedelta(days=i) for i in range(90)])\n",
    "print(arr)\n",
    "dates, cases = covidlive_data(np.datetime64('2021-08-01'))\n",
    "print(dates)\n",
    "print(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "import pyro.distributions as dist\n",
    "\n",
    "def_type = torch.FloatTensor\n",
    "torch.set_default_tensor_type(def_type)\n",
    "\n",
    "pyro.set_rng_seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this helper function does three different things:\n",
    "# (i) plots the observed data;\n",
    "# (ii) plots the predictions from the learned GP after conditioning on data;\n",
    "# (iii) plots samples from the GP prior (with no conditioning on observed data)\n",
    "\n",
    "def plot(plot_observed_data=False, plot_predictions=False, n_prior_samples=0,\n",
    "         model=None, kernel=None, n_test=7, history=114):\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    if plot_observed_data:\n",
    "        plt.plot(X.numpy(), y.numpy(), 'kx')\n",
    "    if plot_predictions:\n",
    "        Xtest = torch.linspace(0, 6, n_test)  # test inputs\n",
    "        # compute predictive mean and variance\n",
    "        with torch.no_grad():\n",
    "            if type(model) == gp.models.VariationalSparseGP:\n",
    "                mean, cov = model(Xtest, full_cov=True)\n",
    "            else:\n",
    "                mean, cov = model(Xtest, full_cov=True, noiseless=False)\n",
    "        sd = cov.diag().sqrt()  # standard deviation at each input point x\n",
    "        plt.plot(Xtest.numpy(), mean.numpy(), 'r', lw=2)  # plot the mean\n",
    "        plt.fill_between(Xtest.numpy(),  # plot the two-sigma uncertainty about the mean\n",
    "                         (mean - 2.0 * sd).numpy(),\n",
    "                         (mean + 2.0 * sd).numpy(),\n",
    "                         color='C0', alpha=0.3)\n",
    "    if n_prior_samples > 0:  # plot samples from the GP prior\n",
    "        Xtest = torch.linspace(0, 6, n_test)  # test inputs\n",
    "        noise = (model.noise if type(model) != gp.models.VariationalSparseGP\n",
    "                 else model.likelihood.variance)\n",
    "        cov = kernel.forward(Xtest) + noise.expand(n_test).diag()\n",
    "        samples = dist.MultivariateNormal(torch.zeros(n_test), covariance_matrix=cov)\\\n",
    "                      .sample(sample_shape=(n_prior_samples,))\n",
    "        plt.plot(Xtest.numpy(), samples.numpy().T, lw=2, alpha=0.4)\n",
    "\n",
    "    plt.xlim(-2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history= len(cases)\n",
    "N = history\n",
    "X = torch.arange(-history, 0, 1, dtype=def_type.dtype)\n",
    "y = torch.as_tensor(cases.copy(), dtype=def_type.dtype)\n",
    "plot(plot_observed_data=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gp.kernels.RBF(input_dim=1, variance=torch.tensor(5., dtype=def_type.dtype),\n",
    "                        lengthscale=torch.tensor(10., dtype=torch.double))\n",
    "gpr = gp.models.GPRegression(X, y, kernel, noise=torch.tensor(1., dtype=def_type.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model=gpr, kernel=kernel, n_prior_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(gpr.parameters(), lr=0.005)\n",
    "loss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n",
    "losses = []\n",
    "num_steps = 2500\n",
    "for i in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(gpr.model, gpr.guide)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model=gpr, plot_observed_data=True, plot_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "kernel = gp.kernels.RBF(input_dim=1, variance=torch.tensor(5., dtype=def_type.dtype),\n",
    "                        lengthscale=torch.tensor(10., dtype=def_type.dtype))\n",
    "gpr = gp.models.GPRegression(X, y, kernel, noise=torch.tensor(1., dtype= def_type.dtype))\n",
    "\n",
    "# note that our priors have support on the positive reals\n",
    "gpr.kernel.lengthscale = pyro.nn.PyroSample(dist.LogNormal(0.0, 1.0))\n",
    "gpr.kernel.variance = pyro.nn.PyroSample(dist.LogNormal(0.0, 1.0))\n",
    "\n",
    "optimizer = torch.optim.Adam(gpr.parameters(), lr=0.005)\n",
    "loss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n",
    "losses = []\n",
    "num_steps = 2500\n",
    "for i in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(gpr.model, gpr.guide)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model=gpr, plot_observed_data=True, plot_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "kernel = gp.kernels.Sum(\n",
    "    gp.kernels.Matern52(\n",
    "        input_dim=1, variance=torch.tensor(5., dtype=def_type.dtype),\n",
    "        lengthscale=torch.tensor(10., dtype=def_type.dtype)),\n",
    "    gp.kernels.Periodic(input_dim=1, variance=torch.tensor(5., dtype=def_type.dtype),\n",
    "        lengthscale=torch.tensor(10., dtype=def_type.dtype),\n",
    "        period=torch.tensor(10., dtype=def_type.dtype),\n",
    "    )\n",
    ")\n",
    "gpr = gp.models.GPRegression(X, y, kernel, noise=torch.tensor(50., dtype= def_type.dtype))\n",
    "\n",
    "# note that our priors have support on the positive reals\n",
    "gpr.kernel.kern0.lengthscale = pyro.nn.PyroSample(dist.Gamma(1, 0.1))\n",
    "gpr.kernel.kern0.variance = pyro.nn.PyroSample(dist.Gamma(2, 0.1))\n",
    "gpr.kernel.kern1.lengthscale = pyro.nn.PyroSample(dist.Gamma(1, 0.1))\n",
    "gpr.kernel.kern1.variance = pyro.nn.PyroSample(dist.Gamma(2, 0.1))\n",
    "gpr.kernel.kern1.period = pyro.nn.PyroSample(dist.Gamma(7, 1))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(gpr.parameters(), lr=0.005)\n",
    "loss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n",
    "losses = []\n",
    "num_steps = 2500\n",
    "for i in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(gpr.model, gpr.guide)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "plt.plot(losses);\n",
    "plot(model=gpr, plot_observed_data=True, plot_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, var = gpr(torch.arange(0,7), full_cov=True)\n",
    "pred_dist = dist.MultivariateNormal(mean, var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dist.log_prob(torch.tensor([200., 200, 200, 200, 200, 200, 200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
