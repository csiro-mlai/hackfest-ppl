{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference in a neural emulation model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look, we can do approximate probabilistic inference with a complicated neural network! Here we will use a 2-million parameter neural net to generate a an approximate likelihood for inference in a model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt, ceil, floor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.functional import F \n",
    "\n",
    "from src.graphs import fno_graph\n",
    "from src.plots import img_plot, multi_img_plot_batch, multi_img_plot_time, multi_heatmap\n",
    "\n",
    "\n",
    "# device = torch.device('cuda')  # I can't make MCMC work on the GPU ðŸ˜¢\n",
    "device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "We have a dataset of snapshots from a [Navier-Stokes](https://en.wikipedia.org/wiki/Navier%E2%80%93Stokes_equations) simulator.\n",
    "\n",
    "This dataset is packed as as $(b, x, y, t)$ i.e. batch first, coordinates in the middle, time last. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/grf_forcing_single.npz')\n",
    "\n",
    "def get_obs(data, t=0, n_steps=2, y=False):\n",
    "    \"\"\"\n",
    "    helper function to parse the data into cunks with teh correct size and names for the model\n",
    "    \"\"\"\n",
    "    x = data['u'][..., t:t+n_steps]\n",
    "    latent = data['f'][...]\n",
    "    obs= {\n",
    "        'x': x,\n",
    "        'latent': latent\n",
    "    }\n",
    "    if y:\n",
    "        obs['y'] = data['u'][..., t+n_steps]\n",
    "\n",
    "    return obs\n",
    "\n",
    "def dict_as_tensor(d, device=device):\n",
    "    \"\"\"\n",
    "    Send a dict of arrays to pytorch tensors.\n",
    "    it was faster to write this function than to search the docs for it\n",
    "    \"\"\"\n",
    "    return {k: torch.as_tensor(v).to(device) for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the data\n",
    "\n",
    "First we look at the snapshots of the simulation. First the vorticity field $x(t)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_img_plot_time(get_obs(data, 0, -1)['x'], n_cols=4, interval=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at the _latent forcing_, which is a time-invariant field that perturbs the dynamics of $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_plot(get_obs(data, 0, -1)['latent']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process predictor model\n",
    "\n",
    "Running a PDE simulator is expensive, so have trained a neural network which can hopefully reproduce these observations, by giving it a data set of 1000 simulations made up of many snapshots. The details of the network are on [Zongyi Liâ€™s blog](https://zongyi-li.github.io/blog/2020/fourier-pde/).\n",
    "\n",
    "NB the data we have here is from the validation set â€” the neural network has not seen this data during the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nn_modules.fourier_2d_generic import SimpleBlock2dGeneric\n",
    "\n",
    "pp_state_dict = torch.load(\n",
    "    './models/fno_forward.ckpt',\n",
    "    map_location=device\n",
    ")\n",
    "process_predictor = SimpleBlock2dGeneric(\n",
    "    modes1=16,\n",
    "    width=24,\n",
    "    n_layers=4,\n",
    "    n_history=2,\n",
    "    param=False,\n",
    "    forcing=False,\n",
    "    latent=True,\n",
    ")\n",
    "process_predictor.load_state_dict(\n",
    "    pp_state_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model maps the vorticity field $x$ at two previous timesteps and the latent forcing field to the vorticity field at the next timestep.\n",
    "We think of the neural network weights $\\theta$ as (some approximation to) the parameters of the model, and we learn them by minimising some predictive error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fno_graph(obs=\"fwd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeatedly invoke this to push the model forward in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_forward(x, latent, n_horizon=1, n_steps=2):\n",
    "    x = torch.as_tensor(x).to(device)\n",
    "    latent = torch.as_tensor(latent).to(device)\n",
    "    process_predictor.to(device)\n",
    "    for i in range(n_horizon):\n",
    "        pred = process_predictor({'x': x[...,-(n_steps):], 'latent': latent})['forecast']\n",
    "        x = torch.cat((x, pred), dim=-1)\n",
    "    return x[...,-n_horizon:]\n",
    "\n",
    "obs = get_obs(data, 0, 10,)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = predict_forward(obs['x'], obs['latent'], n_horizon=50, n_steps=2)\n",
    "\n",
    "multi_img_plot_time(pred.cpu().numpy(), n_cols=5, interval=5);\n",
    "## How the teaser graphic in the README was generated:\n",
    "# plt.savefig('./fno_forward_predict_sheet.jpg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCLAIMER: This is _not_ the most finely tuned of this model â€” in fact it is one with relatively low accuracy because that makes the statistical difficulties of inference easier to see with the naked eye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion by GD\n",
    "\n",
    "Now we want to solve an inverse problem with this model: given some observations of $x(t), x(t-1), x(t-2)$, what is the best guess for the latent forcing field?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fno_graph(obs=\"inverse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can in fact predict and do inversion through the PDE equations directly, but this is _slow_ (hours), so we use the neural network to solve this problem directly.\n",
    "Firstly, we can do this directly as pure predictive error minimisation problem. Forget the probabilistic interpretation of this problem and just minimise some loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasterLatent(nn.Module):\n",
    "    def __init__(self,\n",
    "            process_predictor: \"nn.Module\",\n",
    "            dims = (256,256),\n",
    "            latent_dims = None,\n",
    "            interpolation = 'bilinear',\n",
    "            n_batch: int=1):\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "        if latent_dims is None:\n",
    "            latent_dims = dims\n",
    "        self.latent_dims = latent_dims\n",
    "        self.interpolation = interpolation\n",
    "        self.process_predictor = process_predictor\n",
    "        ## Do not fit the process predictor weights\n",
    "        process_predictor.train(False)\n",
    "        for param in self.process_predictor.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.latent = nn.Parameter(\n",
    "            torch.zeros(\n",
    "                (n_batch, *latent_dims),\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def get_latent(self):\n",
    "        if self.latent_dims==self.dims:\n",
    "            return self.latent\n",
    "        return F.interpolate(\n",
    "            self.latent.unsqueeze(1),\n",
    "            self.dims,\n",
    "            mode=self.interpolation\n",
    "        ).squeeze(1)  #squeeze/unsqueeze is because of weird interpolate semantics\n",
    "\n",
    "    def weights_init(self, scale=0.005):\n",
    "        self.latent.data.normal_(0.0, scale)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch = dict(**batch)\n",
    "        batch['latent'] = self.get_latent()\n",
    "        return self.process_predictor(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "        batch,\n",
    "        model,\n",
    "        optimizer,\n",
    "        n_iter: int=20,\n",
    "        check_int: int=1,\n",
    "        clip_val = None,\n",
    "        init_scale=0.1):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    model.weights_init(init_scale)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    big_loss_fn = nn.MSELoss(reduction='none')\n",
    "    scale = loss_fn(torch.zeros_like(batch['latent']), batch['latent']).item()\n",
    "    for i in range(n_iter):\n",
    "        # Compute prediction error\n",
    "        pred = model(batch)\n",
    "        loss = loss_fn(pred['forecast'], batch['y'])\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if clip_val is not None:\n",
    "            for group in optimizer.param_groups:\n",
    "                torch.nn.utils.clip_grad_value_(group[\"params\"], clip_val)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % check_int == 0 or i==n_iter-1:\n",
    "            with torch.no_grad():\n",
    "                loss_v = loss.item()\n",
    "                # batchwise error\n",
    "                big_error = big_loss_fn(model.get_latent(), batch['latent']).mean(dim=(1,2))\n",
    "                big_relerr = torch.sqrt(big_error/scale)\n",
    "                error = big_error.mean().item()\n",
    "                relerr = sqrt(big_relerr.mean().item())\n",
    "                print(\n",
    "                    f\"loss: {loss:.3e}, error: {error:.3e}, relerror: {relerr:.3e} [{i:>5d}/{n_iter:>5d}]\")\n",
    "\n",
    "                target =  batch['latent'][0, :, :].cpu().numpy()\n",
    "                est =  model.get_latent()[0, :, :].cpu().numpy()\n",
    "                err_heatmap = target - est\n",
    "                multi_heatmap(\n",
    "                    [target, est, err_heatmap],\n",
    "                    [\"Target\", \"Estimate\", \"Error\"])\n",
    "                plt.show();\n",
    "                plt.close(\"all\");\n",
    "\n",
    "    return loss_v, error, relerr, scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RasterLatent(\n",
    "    process_predictor,\n",
    "    dims=obs['x'].shape[1:3],\n",
    "    latent_dims=(16,16),\n",
    "    n_batch=1)\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0025,\n",
    "    weight_decay=0.0)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "fit(\n",
    "    dict_as_tensor(get_obs(data,t=10,n_steps=2,y=True)),\n",
    "    model,\n",
    "    optimizer,\n",
    "    n_iter=50,\n",
    "    check_int=10,\n",
    "    clip_val=None,\n",
    "    init_scale=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic version\n",
    "\n",
    "Here is a selling point of pyro: we can use plain old pytorch neural nets inside pyro inference at it works fine.\n",
    "\n",
    "Documentation for this feature:\n",
    "\n",
    "* [Modules in Pyro â€” Pyro Tutorials](https://pyro.ai/examples/modules.html)\n",
    "* [Neural Networks â€” Pyro documentation](https://docs.pyro.ai/en/stable/nn.html#pyro.nn.module.PyroSample)\n",
    "\n",
    "\n",
    "Let us call the forward operator neural network the _FNO_.\n",
    "We will for the sake of argument, assume it is a good predictor of the expected value of the next timestep from the previous timesteps and latents.\n",
    "We write up an approximate model where the latent field and the forcing field are both perturbed by independent Gaussian noises.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "x(t)(i,j) &\\sim \\mathcal{N}(\\mu(i,j),0.01\\\\\n",
    "\\mu(i,j) &= \\operatorname{FNO}(x(t-2), x(t-1),\\operatorname{latent},{\\theta})(i,j)\\\\\n",
    "\\operatorname{latent}(i,j) &\\sim \\mathcal{N}(0,0.1)\n",
    "\\end{aligned}$$\n",
    "\n",
    "Here the $(i,j)$ notation implies a discretization of the spatial domain; we are going to evaluate this model predictions on a raster grid.\n",
    "In fact, we introduced a discretization already at the neural network training stage, but we make it explicit here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import  MCMC, NUTS\n",
    "from pyro import poutine\n",
    "\n",
    "\n",
    "class ProbRasterLatent(PyroModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            process_predictor: \"nn.Module\",\n",
    "            dims = (256,256),\n",
    "            latent_dims = (16,16),\n",
    "            interpolation = \"bilinear\",\n",
    "            prior_scale = 0.01,\n",
    "            obs_scale = 0.01,):\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "        if latent_dims is None:\n",
    "            latent_dims = dims\n",
    "        self.latent_dims = latent_dims\n",
    "        self.interpolation = interpolation\n",
    "        self.prior_scale = prior_scale\n",
    "        self.obs_scale = obs_scale\n",
    "        self.process_predictor = process_predictor\n",
    "        process_predictor.train(False)\n",
    "        ## Do not fit the process predictor weights\n",
    "        for param in self.process_predictor.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.latent = PyroSample(dist.Normal(0, 0.01).expand(latent_dims).to_event(2))\n",
    "\n",
    "    def get_latent(self):\n",
    "        if self.latent_dims==self.dims:\n",
    "            return self.latent.unsqueeze(0)\n",
    "        l =  F.interpolate(\n",
    "            self.latent.unsqueeze(0).unsqueeze(0),\n",
    "            self.dims,\n",
    "            mode=self.interpolation\n",
    "        ).squeeze(0) #squeeze/unsqueeze is because of weird interpolate semantics\n",
    "        return l\n",
    "\n",
    "    def forward(self, X, y=None):\n",
    "        #overwrite process predictor batch with my own latent\n",
    "        mean = self.process_predictor({\n",
    "            'x': X,\n",
    "            'latent': self.get_latent(),\n",
    "        })['forecast'].squeeze(-1)\n",
    "        # print(\"mean\", mean.shape)\n",
    "        o = pyro.sample(\n",
    "            \"obs\", dist.Normal(mean, self.obs_scale).to_event(2),\n",
    "            obs=y)\n",
    "        # print(\"o\", o)\n",
    "        return o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = dict_as_tensor(get_obs(data, 0, 2, y=True))\n",
    "\n",
    "model = ProbRasterLatent(\n",
    "    process_predictor.to(device),\n",
    "    dims=obs['x'].shape[1:3],\n",
    "    prior_scale=0.01,\n",
    "    obs_scale=0.01,\n",
    ")\n",
    "trace = poutine.trace(model).get_trace(obs['x'], obs['y'])\n",
    "print(trace.format_shapes())\n",
    "\n",
    "model.to(device)\n",
    "nuts_kernel = NUTS(model, full_mass=False, max_tree_depth=5, jit_compile=True) # high performacne config\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=20, warmup_steps=10, num_chains=1)\n",
    "mcmc.run(obs['x'], obs['y'])\n",
    "mc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this probabilistic model is not particularly clever. Would the latent forcing field be well-approximated by i.i.d. Gaussian noise? Probably not. But nonetheless the sample from this field are at least less weird than the non-probabilistic version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_img_plot_batch(mc_samples['latent'], interpolation=\"bilinear\", interval=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, if we take the mean over these samples, we get something that looks more like our target estimand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_plot(mc_samples['latent'].mean(0), interpolation=\"bilinear\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, this is the answer we would ideally like to recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_plot(get_obs(data, 0, -1)['latent']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a little image processing we can compare these images with that error heatmap as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean = F.interpolate(\n",
    "    mcmc.get_samples()['latent'].mean(0).unsqueeze(0).unsqueeze(0),\n",
    "    (256,256),\n",
    "    mode='bilinear').squeeze(0).squeeze(0).detach().cpu().numpy()\n",
    "target = get_obs(data, 0, -1)['latent'].squeeze(0)\n",
    "err = posterior_mean - target\n",
    "multi_heatmap(\n",
    "    [target, posterior_mean, err],\n",
    "    [\"Target\", \"Posterior mean\", \"Error\"])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can probably do better than this.\n",
    "\n",
    "1. HMC is a good default MCMC algorithm, but probably in this case we could try Gibbs sampling to see if it is faster.\n",
    "2. uncorrelated Gaussian noise is not plausible for such a model; we could assume some correlation structure for the latent field.\n",
    "3. this raster grid basis is a little silly. We have reason to suspect that a Fourier basis would be better; however, complex numbers are not well supported by pyro, so I didn't have time to implement all that we needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "887521cc036c2176fc4c7c5fad660bcf5f9a9c2cadfc49851d28bf162a40070d"
  },
  "kernelspec": {
   "display_name": "Cadabra2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
