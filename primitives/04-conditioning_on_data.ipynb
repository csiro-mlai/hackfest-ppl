{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import pyro.distributions as dist\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to and extend [the coin-toss example from the pyro tutorial](http://pyro.ai/examples/svi_part_i.html)\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\operatorname{fairness} &\\sim \\operatorname{Beta}(10,10)\\\\\n",
    "\\operatorname{measurement} &\\sim \\operatorname{Binom}(\\operatorname{fairness}).\n",
    "\\end{aligned}$$\n",
    "\n",
    "We have in fact tossed the coin 100 times in our special coin tossing laboratory, and recorded the data in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some data from our csv file\n",
    "tosses = []\n",
    "with open('coin_tosses.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) #skip header\n",
    "    for row in reader:\n",
    "        tosses.append(int(row[0]))\n",
    "print(tosses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "n_steps =2000\n",
    "\n",
    "assert pyro.__version__.startswith('1.7.0')\n",
    "\n",
    "# clear the param store in case we're in a REPL\n",
    "pyro.clear_param_store()\n",
    "\n",
    "\n",
    "\n",
    "def model(data):\n",
    "    # define the hyperparameters that control the beta prior\n",
    "    alpha0 = torch.tensor(10.0)\n",
    "    beta0 = torch.tensor(10.0)\n",
    "    # sample f from the beta prior\n",
    "    f = pyro.sample(\"latent_fairness\", dist.Beta(alpha0, beta0))\n",
    "    # loop over the observed data\n",
    "    for i in range(len(data)):\n",
    "        # observe datapoint i using the bernoulli likelihood\n",
    "        pyro.sample(\"obs_{}\".format(i), dist.Bernoulli(f), obs=data[i])\n",
    "\n",
    "def guide(data):\n",
    "    # register the two variational parameters with Pyro\n",
    "    # - both parameters will have initial value 15.0.\n",
    "    # - because we invoke constraints.positive, the optimizer\n",
    "    # will take gradients on the unconstrained parameters\n",
    "    # (which are related to the constrained parameters by a log)\n",
    "    alpha_q = pyro.param(\"alpha_q\", torch.tensor(15.0),\n",
    "                         constraint=constraints.positive)\n",
    "    beta_q = pyro.param(\"beta_q\", torch.tensor(15.0),\n",
    "                        constraint=constraints.positive)\n",
    "    # sample latent_fairness from the distribution Beta(alpha_q, beta_q)\n",
    "    pyro.sample(\"latent_fairness\", dist.Beta(alpha_q, beta_q))\n",
    "\n",
    "# setup the optimizer\n",
    "adam_params = {\"lr\": 0.0005, \"betas\": (0.90, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# do gradient steps\n",
    "for step in range(n_steps):\n",
    "    svi.step(data)\n",
    "    if step % 100 == 0:\n",
    "        print('.', end='')\n",
    "\n",
    "# grab the learned variational parameters\n",
    "alpha_q = pyro.param(\"alpha_q\").item()\n",
    "beta_q = pyro.param(\"beta_q\").item()\n",
    "\n",
    "# here we use some facts about the beta distribution\n",
    "# compute the inferred mean of the coin's fairness\n",
    "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
    "# compute inferred standard deviation\n",
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * math.sqrt(factor)\n",
    "\n",
    "print(\"\\nbased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we took an object with a true weight of 8 and got some noisy measurement.\n",
    "We then evaluated the probability of observing that measurement. We can easily\n",
    "use this functionality to plot the PDF of our scale and the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lb = weight - noise * 4\n",
    "ub = weight + noise * 4\n",
    "resolution = 1000\n",
    "measurements = torch.arange(lb, ub, (ub - lb) / resolution)\n",
    "probs = scale_dist.log_prob(measurements).exp()\n",
    "plt.plot(measurements, probs, color=\"red\")\n",
    "ones = torch.ones(100000)\n",
    "multiscale_dist = make_scale_dist(weight * ones, noise * ones)\n",
    "samples = pyro.sample(\"sample\", multiscale_dist)\n",
    "plt.hist(samples.cpu().numpy(), bins=100, density=True, color=\"blue\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PDF looks like a Gaussian centered at $x=8$, and lines up closely with the\n",
    "sample histogram. Now let's examine a more complicated model, where we have a\n",
    "good guess of the object's weight. Mathematically, this becomes\n",
    "\n",
    "$$ \\operatorname{weight} | \\operatorname{guess} \\sim \\mathcal{N}(\\operatorname{guess}, 1) $$\n",
    "\n",
    "$$ \\operatorname{measurement} | \\operatorname{weight} \\sim \\mathcal{N}(\\operatorname{weight}, 0.75) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "pyro.set_rng_seed(101)\n",
    "\n",
    "def model_1(guess):\n",
    "   weight = pyro.sample(\"weight\", dist.Normal(guess, 1.0))\n",
    "   y = pyro.sample(\"measurement\", dist.Normal(weight, 0.75))\n",
    "   return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `trace` class lets us maintain a trace of the entire model, so we can query\n",
    "the particular terms we care about without having to pass them around between\n",
    "different name spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "guess = torch.tensor(7.5)\n",
    "trace_1 = poutine.trace(model_1).get_trace(guess)\n",
    "trace_1.compute_log_prob()\n",
    "nodes =  trace_1.nodes\n",
    "print(f\"weight: {nodes['weight']['value']},\"\n",
    "      f\" probability {nodes['weight']['log_prob'].exp()}\")\n",
    "print(f\"measurement: {nodes['measurement']['value']},\"\n",
    "      f\" probability {nodes['measurement']['log_prob'].exp()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also condition the model to enforce that certain RVs will always have a\n",
    "specific value. This is done with the `condition` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cond_model = pyro.condition(model_1,\n",
    "                            data={\"measurement\": torch.tensor(9.5)})\n",
    "cond_trace = poutine.trace(cond_model).get_trace(guess)\n",
    "cond_trace.compute_log_prob()\n",
    "nodes = cond_trace.nodes\n",
    "print(f\"weight: {nodes['weight']['value']},\"\n",
    "      f\" likelihood {nodes['weight']['log_prob'].exp()}\")\n",
    "print(f\"measurement: {nodes['measurement']['value']},\"\n",
    "      f\" likelihood {nodes['measurement']['log_prob'].exp()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We conditioned the `measurement` RV to evaluate to `9.5` so it was not sampled\n",
    "from its respective distribution. Note, however, that this does not affect the\n",
    "probability of the observation. The probability returned by pyro is\n",
    "$p(measurement = 9.5 | \\mathcal{N}(weight, 0.75)$, and not `1`, even though\n",
    "there was a `100%` chance of `measurement` evaluating to `9.5`. Similarly, if we\n",
    "remove the conditioning on `measurement`, we see that the likelihood of `weight`\n",
    "does not change, even though $p(\\operatorname{weight} | \\operatorname{measurement}) \\neq p(\\operatorname{weight})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cond_model = pyro.condition(model_1,\n",
    "                            data={\"weight\": nodes[\"weight\"][\"value\"]})\n",
    "trace = poutine.trace(cond_model).get_trace(guess)\n",
    "trace.compute_log_prob()\n",
    "weight_node = trace.nodes[\"weight\"]\n",
    "print(f\"weight: {weight_node['value']}, likelihood: {weight_node['log_prob'].exp()}\")\n",
    "\n",
    "measurement_node = trace.nodes[\"measurement\"]\n",
    "print(f\"measurement: {measurement_node['value']}, likelihood: {measurement_node['log_prob'].exp()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to remember that the `condition` function does not actually\n",
    "change the underlying distribution of the RV. Think of it as saying \"let's\n",
    "pretend that we happend to sample `X` for this variable\". Hence, RVs upstream\n",
    "of the conditioned variable do not change their likelihood. The same is not true\n",
    " of downstream RVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trace = poutine.trace(model_1).get_trace(guess)\n",
    "measurements = torch.arange(lb, ub, (ub - lb) / resolution)\n",
    "measurement_dist = trace.nodes['measurement']['fn']\n",
    "probs = measurement_dist.log_prob(measurements).exp()\n",
    "plt.plot(measurements, probs, color=\"blue\")\n",
    "\n",
    "cond_model = pyro.condition(model_1, data={\"weight\": 9})\n",
    "cond_trace = poutine.trace(cond_model).get_trace(guess)\n",
    "cond_dist = cond_trace.nodes['measurement']['fn']\n",
    "cond_probs = cond_dist.log_prob(measurements).exp()\n",
    "plt.plot(measurements, cond_probs, color=\"red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plotted the PDF of `measurement` in both an unconditional model (blue)\n",
    "and a model conditioned on `weight = 9` (red). We can see that conditioning on\n",
    "`weight` changes the probability distribution of the downstream RV\n",
    "`measurement`. Repeatedly executing the above cell will produce a new\n",
    "unconditional PDF every time, because it depends on the stochastic sample from\n",
    "$p(weight | guess=7.5)$. The conditional PDF won't change because it samples\n",
    "deterministically from $p(weight = 9) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://pyro.ai/examples/bayesian_regression.html\n",
    "* http://pyro.ai/examples/bayesian_regression_ii.html\n",
    "* http://pyro.ai/examples/intro_part_i.html\n",
    "* http://pyro.ai/examples/intro_part_ii.html\n",
    "* http://pyro.ai/examples/effect_handlers.html\n",
    "* http://pyro.ai/examples/sir_hmc.html\n",
    "* https://docs.pyro.ai/en/1.7.0/poutine.html\n",
    "* http://pyro.ai/examples/mle_map.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "887521cc036c2176fc4c7c5fad660bcf5f9a9c2cadfc49851d28bf162a40070d"
  },
  "kernelspec": {
   "display_name": "Cadabra2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
