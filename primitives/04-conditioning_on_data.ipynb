{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from pyro import poutine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to the example from a previous notebook. \n",
    "Suppose we want to weigh objects with a faulty scale that has some measurement noise.\n",
    "This follows a simple Gaussian model:\n",
    "\n",
    "$$ \\operatorname{measurement} | \\operatorname{weight} \\sim \\mathcal{N}(\\operatorname{weight}, 0.75).$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_dist(weight, noise):\n",
    "    return dist.Normal(weight, noise)\n",
    "\n",
    "weight, noise = 8, 0.75\n",
    "scale_dist = make_dist(weight, noise)\n",
    "measurement_1 = pyro.sample(\"measurement_1\", scale_dist)\n",
    "prob = scale_dist.log_prob(measurement_1).exp()\n",
    "print(f\"measurement: {measurement_1};\\t likelihood: {prob}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we took an object with a true weight of 8 and got some noisy measurement.\n",
    "We then evaluated the probability of observing that measurement. We can easily\n",
    "use this functionality to plot the PDF of our faulty scale and the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lb = weight - noise * 4\n",
    "ub = weight + noise * 4\n",
    "resolution = 1000\n",
    "measurements = torch.arange(lb, ub, (ub - lb) / resolution)\n",
    "probs = scale_dist.log_prob(measurements).exp()\n",
    "plt.plot(measurements, probs, color=\"red\")\n",
    "ones = torch.ones(100000)\n",
    "multiscale_dist = make_dist(weight * ones, noise * ones)\n",
    "samples = pyro.sample(\"sample\", multiscale_dist)\n",
    "plt.hist(samples.cpu().numpy(), bins=100, density=True, color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PDF looks like a Gaussian centered at $x=8$, and lines up closely with the\n",
    "sample histogram. Now let's examine a more complicated model, where we have a\n",
    "good guess of the object's weight. Mathematically, this becomes\n",
    "\n",
    "$$ \\operatorname{weight} | \\operatorname{guess} \\sim \\mathcal{N}(\\operatorname{guess}, 1) $$\n",
    "\n",
    "$$ \\operatorname{measurement} | \\operatorname{weight} \\sim \\mathcal{N}(\\operatorname{weight}, 0.75) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_1(guess):\n",
    "   weight = pyro.sample(\"weight\", dist.Normal(guess, 1.0))\n",
    "   y = pyro.sample(\"measurement\", dist.Normal(weight, 0.75))\n",
    "   return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `trace` class lets us maintain a trace of the entire model, so we can query\n",
    "the particular terms we care about without having to pass them around between\n",
    "different name space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "guess = torch.tensor(7.5)\n",
    "trace_1 = poutine.trace(model_1).get_trace(guess)\n",
    "trace_1.compute_log_prob()\n",
    "nodes =  trace_1.nodes\n",
    "print(f\"weight: {nodes['weight']['value']},\"\n",
    "      f\" probability {nodes['weight']['log_prob'].exp()}\")\n",
    "print(f\"measurement: {nodes['measurement']['value']},\"\n",
    "      f\" probability {nodes['measurement']['log_prob'].exp()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also condition the model to enforce that certain RVs will always have a\n",
    "specific value. This is done with the `condition` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cond_model = pyro.condition(model_1,\n",
    "                            data={\"measurement\": torch.tensor(9.5)})\n",
    "cond_trace = poutine.trace(cond_model).get_trace(guess)\n",
    "cond_trace.compute_log_prob()\n",
    "nodes = cond_trace.nodes\n",
    "print(f\"weight: {nodes['weight']['value']},\"\n",
    "      f\" likelihood {nodes['weight']['log_prob'].exp()}\")\n",
    "print(f\"measurement: {nodes['measurement']['value']},\"\n",
    "      f\" likelihood {nodes['measurement']['log_prob'].exp()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We conditioned the `measurement` RV to evaluate to `9.5` so it was not sampled\n",
    "from its respective distribution. Note, however, that this does not affect the\n",
    "probability of the observation. The probability returned by pyro is\n",
    "$p(measurement = 9.5 | \\mathcal{N}(weight, 0.75)$, and not `1`, even though\n",
    "there was a `100%` chance of `measurement` evaluating to `9.5`. Similarly, if we\n",
    "remove the conditioning on `measurement`, we see that the likelihood of `weight`\n",
    "does not change, even though $p(\\operatorname{weight} | \\operatorname{measurement}) \\neq p(\\operatorname{weight})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cond_model = pyro.condition(model_1,\n",
    "                            data={\"weight\": nodes[\"weight\"][\"value\"]})\n",
    "trace = poutine.trace(cond_model).get_trace(guess)\n",
    "trace.compute_log_prob()\n",
    "weight_node = trace.nodes[\"weight\"]\n",
    "print(f\"weight: {weight_node['value']}, likelihood: {weight_node['log_prob'].exp()}\")\n",
    "\n",
    "measurement_node = trace.nodes[\"measurement\"]\n",
    "print(f\"measurement: {measurement_node['value']}, likelihood: {measurement_node['log_prob'].exp()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to remember that the `condition` function does not actually\n",
    "change the underlying distribution of the RV. Think of it as saying \"let's\n",
    "pretend that we happend to sample `X` for this variable\". Hence, RVs upstream\n",
    "of the conditioned variable do not change their likelihood. The same is not true\n",
    " of downstream RVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trace = poutine.trace(model_1).get_trace(guess)\n",
    "measurements = torch.arange(lb, ub, (ub - lb) / resolution)\n",
    "measurement_dist = trace.nodes['measurement']['fn']\n",
    "probs = measurement_dist.log_prob(measurements).exp()\n",
    "plt.plot(measurements, probs, color=\"blue\")\n",
    "\n",
    "cond_model = pyro.condition(model_1, data={\"weight\": 9})\n",
    "cond_trace = poutine.trace(cond_model).get_trace(guess)\n",
    "cond_dist = cond_trace.nodes['measurement']['fn']\n",
    "cond_probs = cond_dist.log_prob(measurements).exp()\n",
    "plt.plot(measurements, cond_probs, color=\"red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plotted the PDF of `measurement` in both an unconditional model (blue)\n",
    "and a model conditioned on a `weigh = 9` (red). We can see that conditioning on\n",
    "`weight` changes the probability distribution of the downstream RV\n",
    "`measurement`. Repeatedly executing the above cell will produce a new\n",
    "unconditional PDF every time, because it depends on the stochastic sample from\n",
    "$p(weight | guess=7.5)$. The conditional PDF won't change because it samples\n",
    "deterministically from $p(weight = 9) = 1$"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "887521cc036c2176fc4c7c5fad660bcf5f9a9c2cadfc49851d28bf162a40070d"
  },
  "kernelspec": {
   "display_name": "Cadabra2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
