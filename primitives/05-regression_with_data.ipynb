{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior inference and regression\n",
    "\n",
    "The examples in the previous notebook don’t really show much in the way of fancy prediction; for that we want to do some _regression_.\n",
    "We will follow the [pyro regression tutorial](http://pyro.ai/examples/bayesian_regression.html) but see also the McElreath book for a really nice discussion of this regression problem.\n",
    "\n",
    "* Pyro does not really have a very good explanation for the `Predictive` class that we use here, but [you can work it out from their example](http://pyro.ai/examples/predictive_deterministic.html)\n",
    "* The best introduction is IMO Florian Whilhelm’s [Bayesian Hierarchical Modelling at Scale](https://florianwilhelm.info/2020/10/bayesian_hierarchical_modelling_at_scale/), although that is for the (similar but not identical) numpyro rahter than pyro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive, MCMC, NUTS\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "sns.set_theme()\n",
    "\n",
    "from src import graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data from https://d2hg8soec8ck9v.cloudfront.net/datasets/rugged_data.csv\n",
    "rugged_data = pd.read_csv(\"rugged_data.csv\", encoding=\"ISO-8859-1\")\n",
    "rugged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "df = rugged_data[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]\n",
    "df = df[np.isfinite(df.rgdppc_2000)]\n",
    "df[\"rgdppc_2000\"] = np.log(df[\"rgdppc_2000\"])\n",
    "train = torch.tensor(df.values, dtype=torch.float)\n",
    "is_cont_africa, ruggedness, log_gdp = train[:, 0], train[:, 1], train[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Linear) regression model capturing a predictor variables (Africa or not, Terrain roughness) and a response variable (GDP), and an interaction term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.ruggedness_graph(170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kernel = NUTS(model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc.run(is_cont_africa, ruggedness, log_gdp)\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we need to use the `Predictive` class, which is not well explained in the docs.\n",
    "An only-slightly-confusing explanation is [here](http://pyro.ai/examples/bayesian_regression.html#Model-Evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "def model():\n",
    "    a = pyro.sample(\"a\", dist.Normal(0., 10.))\n",
    "    b_a = pyro.sample(\"bA\", dist.Normal(0., 1.))\n",
    "    b_r = pyro.sample(\"bR\", dist.Normal(0., 1.))\n",
    "    b_ar = pyro.sample(\"bAR\", dist.Normal(0., 1.))\n",
    "    sigma = pyro.sample(\"sigma\", dist.Gamma(1.0, 0.5)) \n",
    "    is_cont_africa = pyro.sample(\"is_cont_africa\", dist.Bernoulli(0.5))\n",
    "    ruggedness = pyro.sample(\"ruggedness\", dist.Normal(1.0, 0.5))\n",
    "    mean = a + b_a * is_cont_africa + b_r * ruggedness + b_ar * is_cont_africa * ruggedness\n",
    "    s = pyro.sample(\"log_gdp\", dist.Normal(mean, sigma))\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "observed_model = poutine.condition(model, data={\n",
    "    \"log_gdp\": log_gdp, \"ruggedness\": ruggedness, \"is_cont_africa\": is_cont_africa})\n",
    "nuts_kernel = NUTS(observed_model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc.run()\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette()\n",
    "swiss_rugged = rugged_data[rugged_data['country']=='Switzerland']['rugged'].item()\n",
    "belgian_rugged = rugged_data[rugged_data['country']=='Belgium']['rugged'].item()\n",
    "swiss_loggdp = np.log(rugged_data[rugged_data['country']=='Switzerland']['rgdppc_2000'].item())\n",
    "belgian_loggdp = np.log(rugged_data[rugged_data['country']=='Belgium']['rgdppc_2000'].item())\n",
    "\n",
    "switzerland2_gdp = Predictive(poutine.condition(model, data={\n",
    "    \"ruggedness\": torch.tensor(swiss_rugged), \"is_cont_africa\": torch.tensor(0.)}), posterior_samples=mcmc.get_samples())()['log_gdp']\n",
    "belgium2_gdp = Predictive(poutine.condition(model, data={\n",
    "    \"ruggedness\": torch.tensor(belgian_rugged), \"is_cont_africa\": torch.tensor(0.)}), posterior_samples=mcmc.get_samples())()['log_gdp']\n",
    "sns.kdeplot(switzerland2_gdp, label=\"Switzerland 2.0 log GDP\", color=colors[0])\n",
    "sns.kdeplot(belgium2_gdp, label=\"Belgium 2.0 log GDP\", color=colors[1])\n",
    "plt.vlines(swiss_loggdp, 0, 0.5, label=\"Switzerland 1.0 log GDP\", linestyle=\"dashed\", color=colors[0])\n",
    "plt.vlines(belgian_loggdp, 0, 0.5, label=\"Belgium 1.0 log GDP\", linestyle=\"dotted\", color=colors[1])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = poutine.trace(model).get_trace()\n",
    "print(trace.format_shapes())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "887521cc036c2176fc4c7c5fad660bcf5f9a9c2cadfc49851d28bf162a40070d"
  },
  "kernelspec": {
   "display_name": "Cadabra2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
