{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior inference and regression\n",
    "\n",
    "The examples in the previous notebook don’t really show much in the way of fancy prediction; for that we want to do some _regression_.\n",
    "See e.g. the McElreath book for a practical intro to regression in a BAyesian context.\n",
    "We will follow the [pyro regression tutorial](http://pyro.ai/examples/bayesian_regression.html).\n",
    "\n",
    "Also good is Florian Whilhelm’s [Bayesian Hierarchical Modelling at Scale](https://florianwilhelm.info/2020/10/bayesian_hierarchical_modelling_at_scale/), although that is for the (similar but not identical) numpyro rather than pyro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import Trace_ELBO, Predictive, MCMC, NUTS\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "sns.set_theme()\n",
    "\n",
    "from src import graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task here is to predict country’s GDP in the year 2000 from various other facts about it. Here are the facts we have to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data from https://d2hg8soec8ck9v.cloudfront.net/datasets/rugged_data.csv\n",
    "rugged_data = pd.read_csv(\"rugged_data.csv\", encoding=\"ISO-8859-1\")\n",
    "rugged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will predict a country’s GDP from its “ruggedness”, and whether it is in Africa  or not, which we observe interact in a non-trivial way.\n",
    "We keep this simple by pre-processing the data (and in fact we work with the log-transformed GDP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "df = rugged_data[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]\n",
    "df = df[np.isfinite(df.rgdppc_2000)]\n",
    "df[\"rgdppc_2000\"] = np.log(df[\"rgdppc_2000\"])\n",
    "train = torch.tensor(df.values, dtype=torch.float)\n",
    "is_cont_africa, ruggedness, log_gdp = train[:, 0], train[:, 1], train[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the model as follows,a (Linear) regression model capturing a predictor variables (Africa or not, Terrain roughness) and a response variable (GDP), and an interaction term.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\text{GDP}_i &\\sim \\mathcal{N}(\\mu, \\sigma)\\\\\n",
    "\\mu &= a + b_a \\cdot \\operatorname{InAfrica}_i + b_r \\cdot \\operatorname{Ruggedness}_i + b_{ar} \\cdot \\operatorname{InAfrica}_i \\cdot \\operatorname{Ruggedness}_i \\\\\n",
    "a &\\sim \\mathcal{N}(0, 1)\\\\\n",
    "b_a &\\sim \\mathcal{N}(0, 1)\\\\\n",
    "b_r &\\sim \\mathcal{N}(0, 1)\\\\\n",
    "b_{ar} &\\sim \\mathcal{N}(0, 1)\\\\\n",
    "\\sigma &\\sim \\operatorname{Gamma}(1, \\frac12)\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $\\alpha$ and $\\beta$ are the coefficients of the intercept and the ruggedness coefficient, respectively, and $\\gamma$ is the coefficient of the binary indicator of whether the country is in Africa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "def model():\n",
    "    a = pyro.sample(\"a\", dist.Normal(0., 10.))\n",
    "    b_a = pyro.sample(\"bA\", dist.Normal(0., 1.))\n",
    "    b_r = pyro.sample(\"bR\", dist.Normal(0., 1.))\n",
    "    b_ar = pyro.sample(\"bAR\", dist.Normal(0., 1.))\n",
    "    sigma = pyro.sample(\"sigma\", dist.Gamma(1.0, 0.5)) \n",
    "    is_cont_africa = pyro.sample(\"is_cont_africa\", dist.Bernoulli(0.5))  # <- overridden\n",
    "    ruggedness = pyro.sample(\"ruggedness\", dist.Normal(1.0, 0.5))        # <- overridden\n",
    "    mean = a + b_a * is_cont_africa + b_r * ruggedness + b_ar * is_cont_africa * ruggedness\n",
    "    s = pyro.sample(\"log_gdp\", dist.Normal(mean, sigma))                 # <- overridden\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the trick here, that we gave distributions even to inputs that we will get from data; this is how you need to do it, even if that distribution will never by used. During inference we  always override the values at those sites with data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.ruggedness_graph(170)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference proceeeds by conditioning the model on the observed data, and then sampling from the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "observed_model = poutine.condition(model, data={\n",
    "    \"log_gdp\": log_gdp, \"ruggedness\": ruggedness, \"is_cont_africa\": is_cont_africa})\n",
    "nuts_kernel = NUTS(observed_model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc.run()\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually make predictions we need to use the `Predictive` class, which is not well explained in the docs, but [you can work it out from their example](http://pyro.ai/examples/predictive_deterministic.html).\n",
    "An only-slightly-confusing explanation is [here](http://pyro.ai/examples/bayesian_regression.html#Model-Evaluation).\n",
    "\n",
    "Now, Let us suppose that we wish to found some new nations, by cutting an existing nation in half so as to preserve its ruggedness. What does this model tell us about the GDP of the new nations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette()\n",
    "swiss_rugged = rugged_data[rugged_data['country']=='Switzerland']['rugged'].item()\n",
    "swiss_loggdp = np.log(rugged_data[rugged_data['country']=='Switzerland']['rgdppc_2000'].item())\n",
    "switzerland2_gdp = Predictive(poutine.condition(model, data={\n",
    "    \"ruggedness\": torch.tensor(swiss_rugged), \"is_cont_africa\": torch.tensor(0.)}), posterior_samples=mcmc.get_samples())()['log_gdp']\n",
    "sns.kdeplot(switzerland2_gdp, label=\"Switzerland 2.0 log GDP\", color=colors[0])\n",
    "plt.vlines(swiss_loggdp, 0, 0.5, label=\"Switzerland 1.0 log GDP\", linestyle=\"dashed\", color=colors[0])\n",
    "\n",
    "pakistan_rugged = rugged_data[rugged_data['country']=='Pakistan']['rugged'].item()\n",
    "pakistan_loggdp = np.log(rugged_data[rugged_data['country']=='Pakistan']['rgdppc_2000'].item())\n",
    "pakistan2_gdp = Predictive(poutine.condition(model, data={\n",
    "    \"ruggedness\": torch.tensor(pakistan_rugged), \"is_cont_africa\": torch.tensor(0.)}), posterior_samples=mcmc.get_samples())()['log_gdp']\n",
    "plt.vlines(pakistan_loggdp, 0, 0.5, label=\"Pakistan 1.0 log GDP\", linestyle=\"dotted\", color=colors[1])\n",
    "sns.kdeplot(pakistan2_gdp, label=\"Pakistan 2.0 log GDP\", color=colors[1])\n",
    "\n",
    "oz_rugged = rugged_data[rugged_data['country']=='Australia']['rugged'].item()\n",
    "oz_loggdp = np.log(rugged_data[rugged_data['country']=='Australia']['rgdppc_2000'].item())\n",
    "oz2_gdp = Predictive(poutine.condition(model, data={\n",
    "    \"ruggedness\": torch.tensor(oz_rugged), \"is_cont_africa\": torch.tensor(0.)}), posterior_samples=mcmc.get_samples())()['log_gdp']\n",
    "plt.vlines(oz_loggdp, 0, 0.5, label=\"Australia 1.0 log GDP\", linestyle=\"dotted\", color=colors[2])\n",
    "sns.kdeplot(oz2_gdp, label=\"Australia 2.0 log GDP\", color=colors[2])\n",
    "\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the predictions are not incredibly informative; since we are working with little information, this model predictions have a high variance, but also the model lets us know that we should not be incredibly confident about them."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "887521cc036c2176fc4c7c5fad660bcf5f9a9c2cadfc49851d28bf162a40070d"
  },
  "kernelspec": {
   "display_name": "Cadabra2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
